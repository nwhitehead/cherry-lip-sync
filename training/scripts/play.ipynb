{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a9050e-9dda-4735-aa05-224e487b6ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import tempfile\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision.io\n",
    "import pyloudnorm as pyln\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Video\n",
    "from IPython.display import Audio\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33527c9a-c849-4716-8b22-4fcda6b76520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ../data import LipsyncDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b7e27-d661-4d8a-ad6a-f5be82fd1452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform = nn.Sequential(Upsample(), AudioMFCC(), PadVisemes())\n",
    "dataset = LipsyncDataset('../data/lipsync.parquet', table=table, transform=None)\n",
    "s = dataset[0]\n",
    "dataset.display_video(0)\n",
    "# AudioMFCC()(s)['audio'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afccc29-29eb-41ed-a626-078cf8151fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = dataset.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88805f2-8d61-4bd2-897d-af31cf46e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab83b87-7a59-4973-94f1-3f4a5078f5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = dataset[0]['visemes'].reshape(1, 1, -1)\n",
    "vv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ea6add-feb3-4f3f-b5b0-f65ec2ea9cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample from 30fps to 100fps\n",
    "# Needs to be float, nearest-exact\n",
    "v100 = torch.nn.Upsample(scale_factor=10/30, mode='nearest-exact')(vv)[0][0]\n",
    "classes = torch.tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
    "classes[v100.to(torch.long)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e386edc-4e7e-4a32-b198-19e3f32cd3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LipsyncDataset('../data/lipsync.parquet', table=table, )#transform=Upsample())\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292559e8-be8a-4cc7-ba62-a09cc2f0ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.display_audio(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdc1ca7-2d78-48d9-8d12-982eb61db706",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.display_video(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df4ebd7-d167-4f27-8519-8dd5a6fb9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0]*3 + [1]*10 + [2]*10 + [0]*3, [1]*3 + [0]*10 + [2]*10 + [1]*3])\n",
    "print(x.shape)\n",
    "f = np.array([1.0, 1.0, -1.0, -1.0])\n",
    "f /= 2\n",
    "#f = f / np.sum(f)\n",
    "y = np.apply_along_axis(np.convolve, axis=1, arr=x, v=f, mode='same')\n",
    "y, x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c366539-cc78-4ad3-a386-4809a2c81416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b40607-ebea-4403-a24d-e1b8a393ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator().manual_seed(42)\n",
    "list(torch.utils.data.random_split(range(10), [3, 7], generator=generator1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1f4c6d-b439-471d-8bd8-0659ed3ab72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e767651-262a-408e-a27a-01a80184bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a966ada-19f9-4e2e-ad84-f6ac760acca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.reshape(2, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dd7807-398a-4d73-a54d-03d41e1077c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27450b5-8538-4cf4-ad90-806cf35442b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0] * 5 + [1] * 3 + [2] + [1] * 5])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f5eb9b-9893-4b8a-bf23-77e1ab1d72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "flash = (x[:, 1:-1] != x[:, :-2]) & (x[:, 1:-1] != x[:, 2:])\n",
    "flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d18a81d-2b8c-4654-b50e-8f619e821f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:, 1:-1][flash] = x[:, :-2][flash]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c2364e-67f0-4e93-a476-1d167b89a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = nn.Sequential(Upsample(), AudioMFCC(), PadVisemes())\n",
    "dataset = LipsyncDataset('../data/lipsync.parquet', table=table, transform=transform)\n",
    "a = dataset[1]['audio']\n",
    "a\n",
    "#numpy_a = a.unsqueeze(0).permute(0, 2, 1).detach().cpu().numpy()\n",
    "#numpy_a[0, 13, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee12fb7-7d4e-4ed3-b61e-512622ea5b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import onnxruntime\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"../data/model-2-80-dropout.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1fdae0-a3ab-47a6-8113-e509abaddc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ort_session.run(None, {'input': numpy_a})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8778b-1918-4005-987b-d961b41708fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, v = torch.max(torch.tensor(np.array(out)), axis=1)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304eafdb-621d-4cec-b5c2-fab641a51437",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d2b6f-80b4-4f01-b396-c1b568cc9bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
